MCDA in Environmental Planning 601cult questions, and the theoretical problem of combin ing conflicting weights from multiple DMs is avoided. However, preferenceinformationfree methods cannot generally provide conclusive solutions to the problems. For example, Electre IV is often not able to produce a single best alternative, and it requires definition of difficult parameters by the analyst. DEA can only sepa rate efficient alternatives from inefficient ones the ef ficiency score should not in general be used for ranking the alternatives. SMAA methods provide the most de tailed information describing what kind of preferences correspond to the choice of each alternative. SMAA provides this information in the form of socalled ac ceptability indices that measure the variety of different preferences supporting each alternative, and central weights describing the preferences of a typical DM supporting a certain alternative. SMAA can be used for identifying good compromise alternatives that are ac ceptable to many stakeholders with different prefer ences. It important to note that such alternatives are likely to remain good solutions in the future also, sub ject to changing preferences, new stakeholders, and changing or more accurate criteria. In utilityfunctionbased methods, the uncertainty and inaccuracy of the problem data can be modeled using intervals or stochastic distributions. In general, stochastic models must be analyzed numerically using Monte Carlo simulation. In outranking approaches, the inaccuracy can be modeled through the indifference and preference thresholds (socalled pseudocriteria). Of course, threshold values must be assessed for each criterion and for each problem separately. The SMAA methods can be used with any decision model that uses weights. Thus, the uncertainty can be modeled using either stochastic criteria (SMAA, SMAA2, and SMAAD) or pseudocriteria (SMAA3). With stochastic criteria, SMAA provides socalled confidence factors, which measure explicitly whether the data are accurate enough for making informed decisions. The use of pseudocriteria in association with out ranking methods may result in many mutually indiffer ent or incomparable alternatives (incomparability may occur only with the socalled distillation process, which may be used in the aggregation phase of Electre meth ods). Thus, no complete ranking of the alternatives is obtained. The incomparability between some alterna tives can be considered a weakness of the method when it is not able to rank the alternatives completely. Incom parability can also be seen as a way to represent deci sion situations where the DM indeed is unable to com pare some alternatives. If there is no basis to compare two alternatives reliably, they should be accepted as being incomparable. This is also one way to protect;cult questions, and the theoretical problem of combin ing conflicting weights from multiple DMs is avoided. However, preferenceinformationfree methods cannot generally provide conclusive solutions to the problems. For example, Electre IV is often not able to produce a single best alternative, and it requires definition of difficult parameters by the analyst. DEA can only sepa rate efficient alternatives from inefficient ones the ef ficiency score should not in general be used for ranking the alternatives. SMAA methods provide the most de tailed information describing what kind of preferences correspond to the choice of each alternative. SMAA provides this information in the form of socalled ac ceptability indices that measure the variety of different preferences supporting each alternative, and central weights describing the preferences of a typical DM supporting a certain alternative. SMAA can be used for identifying good compromise alternatives that are ac ceptable to many stakeholders with different prefer ences. It important to note that such alternatives are likely to remain good solutions in the future also, sub ject to changing preferences, new stakeholders, and changing or more accurate criteria. In utilityfunctionbased methods, the uncertainty and inaccuracy of the problem data can be modeled using intervals or stochastic distributions. In general, stochastic models must be analyzed numerically using Monte Carlo simulation. In outranking approaches, the inaccuracy can be modeled through the indifference and preference thresholds (socalled pseudocriteria). Of course, threshold values must be assessed for each criterion and for each problem separately. The SMAA methods can be used with any decision model that uses weights. Thus, the uncertainty can be modeled using either stochastic criteria (SMAA, SMAA2, and SMAAD) or pseudocriteria (SMAA3). With stochastic criteria, SMAA provides socalled confidence factors, which measure explicitly whether the data are accurate enough for making informed decisions. The use of pseudocriteria in association with out ranking methods may result in many mutually indiffer ent or incomparable alternatives (incomparability may occur only with the socalled distillation process, which may be used in the aggregation phase of Electre meth ods). Thus, no complete ranking of the alternatives is obtained. The incomparability between some alterna tives can be considered a weakness of the method when it is not able to rank the alternatives completely. Incom parability can also be seen as a way to represent deci sion situations where the DM indeed is unable to com pare some alternatives. If there is no basis to compare two alternatives reliably, they should be accepted as being incomparable. This is also one way to protectstakeholders points of view in environmental planning processes. The decision model determines the compensation between the criteria (see, e.g., Bouyssou 1986). A linear valueutility model provides full compensation be tween the criteria, i.e., a poor value on any criterion can be compensated by a sufficiently good value on another criterion. Compensation can be decreased by using nonlinear utility models. However, this leads to the difficult problem of determining the correct shape. Outranking methods typically do not provide full com pensation. Due to the thresholds used, not all differ ences among criteria values affect the analysis.;Commonly, in multicriteria problems a number is assigned for each criterion describing its importance. These numbers are called weights, and they model the DMs subjective preferences. The interpretation of the weights depends completely on the decision model. Therefore, it is essential that the decision model be chosen prior to collecting weights (see, e.g., Vincke 1992). In decision models based on utility theory, the weights are used for aggregating criteria values into a single number describing the overall goodness or utility of each alternative. The interpretation of the weights depends on the shape of the utility function. The most commonly used linear utility function uses the weights to compute the utilities as weighted (arithmetic) aver ages of suitably scaled criteria. The weights can then be interpreted as pricecoefficients for criteria, and ratios between weights represent tradeoff ratios between cri teria. An additive utility function first maps criteria values by partial utility functions onto the interval 0, 1 and then computes the overall utilities as a weighted average of the partial utilities. As the partial utility functions may be nonlinear, the weights then corre spond to nonconstant price functions for criteria, and weight ratios represent variable tradeoff ratios between criteria. The interpretation of weights in more complex utility functions becomes exceedingly difficult. In the outranking approach the interpretation of weights is completely different the weights are considered as votes for certain criteria (Roy 1991). Weight information can be more or less accurate. When exact weights cannot be obtained or agreed on, weight intervals or weight distributions can be used. Sometimes only partial priority information between criteria is available. The DMs may also refuse to provide any weight information. When the number of DMs is small, it is possible to use weightassessing techniques with several consistency checks. When the number of